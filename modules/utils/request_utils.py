import requests
from loguru import logger
import json
from concurrent.futures import ThreadPoolExecutor

def request_paginated_data(
    url, base_params, key_name, date_key=None, date_value=None, page_size=100, max_pages=100
):
    """
    í˜ì´ì§• ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìš”ì²­í•˜ì—¬ ëª¨ë‘ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        url (str): ìš”ì²­í•  API URL
        base_params (dict): ê¸°ë³¸ ìš”ì²­ íŒŒë¼ë¯¸í„° (API í‚¤ ë“±)
        key_name (str): ì‘ë‹µ JSONì—ì„œ ì‹¤ì œ ë°ì´í„°ê°€ ë‹´ê¸´ key ì´ë¦„
        date_key (str, optional): íŠ¹ì • ë‚ ì§œ í•„í„°ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ì´ë¦„ (ì˜ˆ: "CONF_DATE")
        date_value (str, optional): ë‚ ì§œ í•„í„°ë¡œ ì‚¬ìš©í•  ê°’
        page_size (int, optional): í˜ì´ì§€ë‹¹ ë°ì´í„° ê°œìˆ˜. ê¸°ë³¸ê°’ì€ 100
        max_pages (int, optional): ìµœëŒ€ í˜ì´ì§€ ìˆ˜. ê¸°ë³¸ê°’ì€ 100

    Returns:
        list: ìˆ˜ì§‘ëœ ì „ì²´ row ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    all_data = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = executor.map(
            lambda idx: _fetch_single_page(url, base_params, key_name, date_key, date_value, page_size, idx),
            range(1, max_pages + 1)
        )
        for rows in futures:
            if not rows:
                break
            all_data.extend(rows)
    return all_data

def _fetch_single_page(url, base_params, key_name, date_key, date_value, page_size, pIndex):
    params = base_params.copy()
    params["pIndex"] = str(pIndex)
    params["pSize"] = str(page_size)
    if date_key and date_value:
        params[date_key] = date_value

    logger.debug(f"â¡ï¸ ìš”ì²­ íŒŒë¼ë¯¸í„°: {params}")
    try:
        response = requests.get(url=url, params=params, timeout=10)
        logger.info(f"ğŸ“¡ ìš”ì²­ ì¤‘... pIndex={pIndex}, ìš”ì²­ URL: {response.request.url}")
        response.raise_for_status()
        data = response.json()

        if "RESULT" in data and data["RESULT"]["MESSAGE"] == "í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.":
            logger.warning(f"ğŸ“¢ ë°ì´í„° ì—†ìŒ, pIndex={pIndex}")
            return []

        if key_name not in data:
            logger.error(f"âŒ ì˜ˆìƒëœ í‚¤({key_name})ê°€ ì‘ë‹µ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            return []

        rows = data[key_name][1]["row"]
        logger.info(f"âœ… {pIndex} í˜ì´ì§€ ë°ì´í„° ì¶”ê°€ (ì´ {len(rows)}ê°œ)")
        return rows
    except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError, IndexError) as e:
        logger.error(f"âŒ í˜ì´ì§€ {pIndex} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return []
    