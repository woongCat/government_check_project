# modules/extract/pdf_url_extractor.py
from concurrent.futures import ThreadPoolExecutor, as_completed

from modules.constants.config import OPEN_GOVERMENT_API_KEY
from modules.base.base_extractor import BaseExtractor
from modules.utils.request_utils import request_paginated_data


class PDFUrlExtractor(BaseExtractor):
    """_summary_

    Args:
        url (_type_): _ì„¤ì •ëœ PDF URL API URL_
        meeting_date_list (_type_): ì´ê±° ë•Œë¬¸ì— fetch_scheduleì„ í†µí•´ì„œ scheduleì„ ê°€ì ¸ì™€ì•¼ í•¨
        unit_cd (str, optional): êµ­íšŒì˜ì› ì„ ê±° ë²ˆí˜¸ fetch_scheduleì´ë‘ì€ ë˜ ë‹¤ë¦„. Defaults to "22".
        page_size (int, optional): í˜ì´ì§€ì˜ í¬ê¸°. Defaults to 100.
        max_pages (int, optional): ìµœëŒ€ í˜ì´ì§€ ìˆ˜. Defaults to 10.

    Returns:
        _type_: _description_
    """

    def __init__(self, url, meeting_dates, unit_cd="22", page_size=100, max_pages=10):
        self.url = url
        self.meeting_dates = meeting_dates
        self.unit_cd = unit_cd
        self.page_size = page_size
        self.max_pages = max_pages

    def extract(self):
        self.log_info("PDF URL ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
        key_name = self.url[43:]
        base_params = {
            "KEY": OPEN_GOVERMENT_API_KEY,
            "Type": "json",
            "DAE_NUM": self.unit_cd,
        }
        all_data, fetched_dates = [], set()

        def fetch_by_date(date):
            return date, request_paginated_data(
                self.url,
                base_params,
                key_name,
                date_key="CONF_DATE",
                date_value=date,
                page_size=self.page_size,
                max_pages=self.max_pages,
            )

        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(fetch_by_date, date) for date in self.meeting_dates
            ]
            for future in as_completed(futures):
                date, page_data = future.result()
                if page_data:
                    fetched_dates.add(date)
                    all_data.extend(page_data)

        self.log_info(f"ğŸ“Œ ì „ì²´ PDF URL ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ {len(all_data)}ê°œ ìˆ˜ì§‘")
        return all_data, sorted(fetched_dates)
